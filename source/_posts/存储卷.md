---
title: 存储卷
date: 2021-01-27 10:17:54
tags:
---



- Pod:
  - spec.volumes
    - 直接定义设备参数
    - pvc 
      - 标签匹配pv
      - 存储类，动态供给pv
    - 特殊类型的存储卷
      - configmap
      - secret
  - spec.containers[].volumeMounts

<!--more-->

# 为什么使用存储卷

容器跨节点运行，原有镜像会删除，在另一个节点上重建容器，会导致此前容器中的数据在原节点。

镜像本身是只读的，所有写操作在镜像栈最上面的**可写层**，可写层在节点上，删除容器可写层也会被删除，就需要存储卷。

- docker存储卷
  - 绑定挂载卷：    节点路径自已指定
  - docker存储卷：docker自行管理卷

  

kuberenetes Pod跨节点运行，使用本地存储卷，数据在本节点上，如果Pod重建被调度至其他节点，其他节点没有这个存储卷。

- Kubernetes存储卷
  - nfs存储：emc、...；nfs需要数据同步(rsync+inotify), 性能低。**节点冗余**
    - 容器共享节点内核，确保节点内核可以连接nfs server.
  - 分布式存储：存储服务自身有数据冗余，有扩展能力。 **数据级冗余**
    - 需要存储工程师
    - 不需要存储工程师：公有云，10个虚拟机，跑K8S；或直接买云存储。**Aliyun**的云盘（存储卷服务），通过快照方式保证数据可用性。aliyun, 七牛云



# Volumes

K8S存储卷不属于容器，而是属于Pod。

Pod中同享uts、network、IPC

加入到pod容器，可以复制`--volumes-from`pause的存储卷

![image-20210128093533362](http://myapp.img.mykernel.cn/image-20210128093533362.png)



CSI：container storage interface, 避免k8s内置存储驱动, 用户可以自定义使用任何类型存储插件。

为了降低用户使用难度，K8S内置了一些存储类型，要使用存储驱动：1. 节点支持驱动。 2. 使用驱动

```bash
#K8S 内建插件， 支持存储系统
# 如果没有，就需要CSI扩展K8S支持的存储
[root@master ~]# kubectl explain pod.spec.volumes
KIND:     Pod
VERSION:  v1

RESOURCE: volumes <[]Object> # 对象列表

DESCRIPTION:
     List of volumes that can be mounted by containers belonging to the pod.
     More info: https://kubernetes.io/docs/concepts/storage/volumes

     Volume represents a named volume in a pod that may be accessed by any
     container in the pod.
   awsElasticBlockStore	<Object> #
   azureDisk	<Object> # 块 微软
   azureFile	<Object> # 文件
   cephfs	<Object>   # cehp
   cinder	<Object> # openstack存储服务
   configMap	<Object> # configmap
   csi	<Object>
   downwardAPI	<Object> 
   emptyDir	<Object> # 空存储卷，缓存
   ephemeral	<Object>
   fc	<Object> # 光纤
   flexVolume	<Object>
   flocker	<Object>
   gcePersistentDisk	<Object> # google块存储
   gitRepo	<Object> 
   glusterfs	<Object> # glusterfs
   hostPath	<Object> # 节点
   iscsi	<Object> # 网络
   name	<string> -required-
   nfs	<Object> # nfs
   persistentVolumeClaim	<Object> # pvc
   photonPersistentDisk	<Object>
   portworxVolume	<Object>
   projected	<Object>
   quobyte	<Object>
   rbd	<Object> # ceph块
   scaleIO	<Object>
   secret	<Object> # secret 
   storageos	<Object> 
   vsphereVolume	<Object>

```

## volume存储分类

- 云存储                   **付费**
  - aws
  - azure
  - gce
  - vshpere
  - cinder
- 分布式 红帽下            **买人的服务**
  - ceph
  - rdb
  - glusterfs
- 网络
  - nfs      NAS
  - iscsi     SAN 
  - fc          SAN
- 临时  生命周期同Pod
  - emptydir
  - gitrepo
- 本地存储 生命周期同节点，pod重建在另一个节点上也没有数据
  - hostpath
  - local
- 特殊
  - cm
  - secret
  - downwardapi
- 自定义
  - csi
- 持久存储卷
  - pvc

## Pod如何存储卷？

- [x] 存储系统存在；存在nfs server
- [x] pod级别定义使用存储系统服务；spec.volumes
- [x] Pod容器挂载存储卷: spec.containers[].volumeMounts

```bash
# 使用节点本地使用目录管理
[root@master ~]# kubectl explain pod.spec.volumes.hostPath
KIND:     Pod
VERSION:  v1

RESOURCE: hostPath <Object>

DESCRIPTION:
     HostPath represents a pre-existing file or directory on the host machine
     that is directly exposed to the container. This is generally used for
     system agents or other privileged things that are allowed to see the host
     machine. Most containers will NOT need this. More info:
     https://kubernetes.io/docs/concepts/storage/volumes#hostpath

     Represents a host path mapped into a pod. Host path volumes do not support
     ownership management or SELinux relabeling.

FIELDS:
   path	<string> -required- # 节点路径
     Path of the directory on the host. If the path is a symlink, it will follow
     the link to the real path. More info:
     https://kubernetes.io/docs/concepts/storage/volumes#hostpath

   type	<string> # 万一目录不存在怎么办
   		
     Type for HostPath Volume Defaults to "" More info:
     https://kubernetes.io/docs/concepts/storage/volumes#hostpath

```

type值

| Value               | Behavior                                                     |
| :------------------ | :----------------------------------------------------------- |
|                     | Empty string (default) is for backward compatibility, which means that no checks will be performed before mounting the hostPath volume. |
| `DirectoryOrCreate` | 节点目录如果不存在，自动新建。755，属主或属组与kubelet相同。 |
| `Directory`         | 节点目录必须存在。                                           |
| `FileOrCreate`      | 节点文件如果不存在，自动新建。755，属主或属组与kubelet相同。 |
| `File`              | 宿主机必须是存在的文件。                                     |
| `Socket`            | A UNIX socket must exist at the given path                   |
| `CharDevice`        | A character device must exist at the given path              |
| `BlockDevice`       | A block device must exist at the given path                  |



挂载存储卷

```bash
[root@master ~]# kubectl explain pod.spec.containers.volumeMounts
KIND:     Pod
VERSION:  v1

RESOURCE: volumeMounts <[]Object> # 对象列表

DESCRIPTION:
     Pod volumes to mount into the container's filesystem. Cannot be updated.

     VolumeMount describes a mounting of a Volume within a container.
   mountPath	<string> -required- # 容器挂载点
   mountPropagation	<string>        
   name	<string> -required-         # 挂载哪个名称的存储卷
   readOnly	<boolean>               # 挂载之后只读？默认读写
   subPath	<string>
   subPathExpr	<string>

```



### 目录hostPath

vol-demo.yaml

```bash
# kubectl run -n vol myapp --image=a --dry-run -o yaml > vol-demo.yaml

"vol-demo.yaml" 16L, 245C                                                                                                       
apiVersion: v1
kind: Pod
metadata:
  labels:
    app: myapp       # app标签方便deploy/svc引用
  name: myapp
  namespace: vol
spec:
  volumes:
  - name: webstor
    hostPath:
      type: DirectoryOrCreate
      path: /volumes/myapp
  containers:
  - image: ikubernetes/myapp:v1 # nginx, 默认网页/usr/share/nginx/html
    name: myapp
    resources: {}
    volumeMounts: # kubectl explain pod.spec.containers.volumeMounts
    - name: webstor
      mountPath: /usr/share/nginx/html
      readOnly: true            # 只读
  dnsPolicy: ClusterFirst
  restartPolicy: Always      #  重启策略, onfailure exit !0, 重启。     Always停了就重启
```

启动

```bash
[root@master volumes]# kubectl create ns vol
namespace/vol created
[root@master volumes]# kubectl apply -f vol-demo.yaml
pod/myapp created
[root@master volumes]# kubectl get pod -n vol
NAME    READY   STATUS    RESTARTS   AGE
myapp   1/1     Running   0          31s
[root@master volumes]# kubectl describe pod -n vol myapp
Containers: # 容器内部
  myapp: # myapp容器
    Container ID:   docker://895208cfb1082d4063f7902bf7c82450bcae1b65ece86f5a70050d2e3334e2cf
    Image:          ikubernetes/myapp:v1
    Image ID:       docker-pullable://ikubernetes/myapp@sha256:9c3dc30b5219788b2b8a4b065f548b922a34479577befb54b03330999d30d513
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Thu, 28 Jan 2021 10:00:01 +0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts: # 容器挂载
    	# 容器路径                 # 卷名  只读
      /usr/share/nginx/html from webstor (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rwpm5 (ro)
Volumes:
  webstor:
    Type:          HostPath (bare host directory volume) # 类型
    Path:          /volumes/myapp            # 宿主机路径 
    HostPathType:  DirectoryOrCreate         # 类型
  default-token-rwpm5:                       # secret
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-rwpm5
    Optional:    false



# pod调度节点
[root@master volumes]# kubectl get pods -n vol -o wide
NAME    READY   STATUS    RESTARTS   AGE     IP            NODE                NOMINATED NODE   READINESS GATES
myapp   1/1     Running   0          2m37s   10.244.1.15   node01.magedu.com   <none>           <none>


# node01验证
[root@node01 ~]# ll /volumes/myapp/
total 0

# 访问主页
[root@master volumes]# curl 10.244.1.15
<html>
<head><title>403 Forbidden</title></head>
<body bgcolor="white">
<center><h1>403 Forbidden</h1></center>
<hr><center>nginx/1.12.2</center>
</body>
</html>

# 在运行pod的主机创建主页
echo '<h1>page @ volumes</h1>' > /volumes/myapp/index.html

# 再次访问
[root@master volumes]# curl 10.244.1.15
<h1>page @ volumes</h1>

```

> 所以只要pod删除后重建仍在这个节点，还可以访问数据

将pod绑定在节点上，这样资源高效利用相违背

```diff
"vol-demo.yaml" 23L, 656C                                                                                                                                                                                                                                                                                20,7          All
apiVersion: v1
kind: Pod
metadata:
  labels:
    app: myapp       # app标签方便deploy/svc引用
  name: myapp
  namespace: vol
spec:
+  nodeName: node01.magedu.com # 固定
  volumes:
  - name: webstor
    hostPath:
      type: DirectoryOrCreate
      path: /volumes/myapp
  containers:
  - image: ikubernetes/myapp:v1 # nginx, 默认网页/usr/share/nginx/html
    name: myapp
    resources: {}
    volumeMounts: # kubectl explain pod.spec.containers.volumeMounts
    - name: webstor
      mountPath: /usr/share/nginx/html
      readOnly: true            # 只读
  dnsPolicy: ClusterFirst
  restartPolicy: Always      #  重启策略, onfailure exit !0, 重启。     Always停了就重启

```

### local

k8s v1.10 beta



### emptydir

hostPath，pod删除了，数据在节点上

emptydir使用的原因

- [x] 容器需要缓存，节点上的ssd、节点上的内存模拟成硬盘
- [x] 容器间需要共享数据部分数据：可以共享ipc/network/uts, 不能共享mount

```bash
[root@master volumes]# kubectl explain pod.spec.volumes.emptyDir
KIND:     Pod
VERSION:  v1

RESOURCE: emptyDir <Object>

DESCRIPTION:
     EmptyDir represents a temporary directory that shares a pod's lifetime.
     More info: https://kubernetes.io/docs/concepts/storage/volumes#emptydir

     Represents an empty directory for a pod. Empty directory volumes support
     ownership management and SELinux relabeling.

FIELDS:
   medium	<string>
     默认空目录(节点做成SSD)，也可以使用Memory

   sizeLimit	<string>
	如果定义Memory，必须应该定义大小
```



```diff
[root@master ~]# cd Kubernetes_Advanced_Practical/chapter7/
[root@master chapter7]# cat vol-emptydir.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: vol-emptydir-pod
+  namespace: vol
spec:
  volumes:
  - name: html # 定义
    emptyDir: {}
  containers:
  - name: nginx
+    image: ikubernetes/myapp:v1
    volumeMounts:
    - name: html # 挂载为网页目录
      mountPath: /usr/share/nginx/html
  - name: pagegen
    image: alpine
    volumeMounts:
    - name: html # 挂载后，生成网页文件
      mountPath: /html
+    command: ["/bin/sh", "-c"] # 自定义命令
+    args:                      # 自定义传给命令的参数
    - while true; do
        echo $(hostname) $(date) >> /html/index.html;
+        sleep 10;               # 实验快速生成
      done
```

```bash
[root@master chapter7]# kubectl apply -f vol-emptydir.yaml
pod/vol-emptydir-pod created
[root@master chapter7]# kubectl get pod -n vol  -o wide
NAME               READY   STATUS    RESTARTS   AGE   IP            NODE                NOMINATED NODE   READINESS GATES
myapp              1/1     Running   0          72m   10.244.1.15   node01.magedu.com   <none>           <none>
vol-emptydir-pod   2/2     Running   0          27s   10.244.3.41   node03.magedu.com   <none>           <none>

[root@master chapter7]# kubectl describe pod vol-emptydir-pod -n vol
Containers:
  nginx:
    Container ID:   docker://814fb9c8bcd6140bd799b389cee6812fc0f4e18637e47bd0c64a869b8e447f4a
    Image:          ikubernetes/myapp:v1
    Image ID:       docker-pullable://ikubernetes/myapp@sha256:9c3dc30b5219788b2b8a4b065f548b922a34479577befb54b03330999d30d513
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Thu, 28 Jan 2021 11:11:55 +0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
    	# 第1个容器挂载html
      /usr/share/nginx/html from html (rw) 
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rwpm5 (ro)
  pagegen:
    Container ID:  docker://7f18b889c4eb1f9b6fe5df402867b5a3899771c81a10f17995022889ab48ce21
    Image:         alpine
    Image ID:      docker-pullable://alpine@sha256:d9a7354e3845ea8466bb00b22224d9116b183e594527fb5b6c3d30bc01a20378
    Port:          <none>
    Host Port:     <none>
    Command:
      /bin/sh
      -c
    Args:
      while true; do echo $(hostname) $(date) >> /html/index.html; sleep 10; done
    State:          Running
      Started:      Thu, 28 Jan 2021 11:12:02 +0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
    	# 第2个容器挂载html
      /html from html (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rwpm5 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  html: # 定义卷
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  default-token-rwpm5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-rwpm5
    Optional:    false
QoS Class:       BestEffort

# 访问
[root@master chapter7]# curl 10.244.3.41
vol-emptydir-pod Thu Jan 28 03:12:02 UTC 2021
vol-emptydir-pod Thu Jan 28 03:12:12 UTC 2021
vol-emptydir-pod Thu Jan 28 03:12:22 UTC 2021
vol-emptydir-pod Thu Jan 28 03:12:32 UTC 2021
# 经过10s，自动生成
[root@master chapter7]# curl 10.244.3.41
vol-emptydir-pod Thu Jan 28 03:12:02 UTC 2021
vol-emptydir-pod Thu Jan 28 03:12:12 UTC 2021
vol-emptydir-pod Thu Jan 28 03:12:22 UTC 2021
vol-emptydir-pod Thu Jan 28 03:12:32 UTC 2021
vol-emptydir-pod Thu Jan 28 03:12:42 UTC 2021
```



### 独立于节点外的存储

K8S主流存储

- [x] cephfs 文件接口
- [x] rbd       块
- [x] rgw      对象



生产环境中不使用NFS，以下使用nfs做实验。

可以买存储，有能力维护ceph



这样就可以实现脱离节点生命周期的存储，其他存储除了配置格式不一样，实现结果一样。

除了存储提供的冗余能力、IO性能不一样

不同存储维护成本不一样



使用存储，你得去配置存储的各个参数，https://github.com/kubernetes/examples/tree/master/volumes/cephfs/

一旦安装了Ceph和Kubernetes集群，就可以基于我的示例[cephfs.yaml](https://github.com/kubernetes/examples/blob/master/volumes/cephfs/cephfs.yaml) 和[cephfs-with-secret.yaml](https://github.com/kubernetes/examples/blob/master/volumes/cephfs/cephfs-with-secret.yaml)创建一个pod 。在pod yaml中，您需要提供以下信息。

- *monitors*：Ceph监视器的数组。
- *path*：用作安装的根，而不是完整的Ceph树。如果未提供，则使用默认值*/*。
- *user*：RADOS用户名。如果未提供，则使用默认*管理员*。
- *secretFile*：密钥环文件的路径。如果未提供，则使用默认的*/etc/ceph/user.secret*。
- *secretRef*：对Ceph身份验证机密的引用。如果提供，则*secret*覆盖*secretFile*。
- *readOnly*：文件系统是否用作readOnly。

这样你使用pod的存储卷时，就得你得学习存储怎么连接。**k8s只需要多大空间，不关心存储从哪儿来，用户只需要消费。这就需要用到PV/PVC**



配置nfs服务

```bash
# 克隆node04
# for i in 4; do bash safe_clone_kvm.sh -i /VMs/template/centos7.5-1804-2C2G.qcow2 -d /VMs/kubernetes/centos-172.16.1.10${i}.qcow2  -t kvm  -n centos-172.16.1.10${i} -r 2048  -v 2 -b vmbr0; done

#virsh console 64
# 配置ip

[root@localhost ~]# yum -y install nfs-utils

install -dv /vols/{1..5}

"/etc/exports" 0L, 0C                                                                                                           
/vols 172.16.0.0/16(rw,no_root_squash)


systemctl enable nfs --now
[root@localhost ~]# exportfs  -arv
exporting 172.16.0.0/16:/vols

[root@localhost ~]# systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
[root@localhost ~]# systemctl stop firewalld
[root@localhost ~]# iptables -vnL
Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination         

Chain FORWARD (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination         

Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination         
```



在k8s节点上可以驱动nfs

```bash
# 各节点安装nfs-utils
yum -y install nfs-utils

# 节点级测试挂载
[root@node01 ~]# mount -t nfs 172.16.1.104:/vols/1 /mnt
[root@node01 ~]# df -TH
Filesystem           Type      Size  Used Avail Use% Mounted on
172.16.1.104:/vols/1 nfs4      115G  1.3G  114G   2% /mnt # 挂载成功

# 卸载
[root@node01 ~]# umount /mnt
```



使用nfs存储卷

```bash
[root@master ~]# kubectl explain pods.spec.volumes.nfs
KIND:     Pod
VERSION:  v1

RESOURCE: nfs <Object>

DESCRIPTION:
     NFS represents an NFS mount on the host that shares a pod's lifetime More
     info: https://kubernetes.io/docs/concepts/storage/volumes#nfs

     Represents an NFS mount that lasts the lifetime of a pod. NFS volumes do
     not support ownership management or SELinux relabeling.

FIELDS:
   path	<string> -required- # nfs 路径

   readOnly	<boolean> #只读

   server	<string> -required-  # nfs 地址和端口

```

```diff
[root@master chapter7]# cat vol-nfs.yaml
apiVersion: v1
kind: Pod
metadata:
  name: vol-nfs-pod
+  namespace: vol
  labels:
    app: redis
spec:
  containers:
  - name: redis # redis
    image: redis:alpine
    ports:
    - containerPort: 6379
      name: redisport # redis端口为redisport
    volumeMounts: # 挂载redisdata卷名
    - mountPath: /data # redis镜像，默认snapshot持久路径在/data
      name: redisdata
  volumes:
    - name: redisdata # 定义卷名
      nfs:
+        server: 172.16.1.104 # server
+        path: /vols/1

```



```bash
[root@master chapter7]# kubectl apply -f vol-nfs.yaml
pod/vol-nfs-pod created
[root@master chapter7]# kubectl get pod -n vol -o wide
NAME               READY   STATUS    RESTARTS   AGE   IP            NODE                NOMINATED NODE   READINESS GATES
myapp              1/1     Running   0          92m   10.244.1.15   node01.magedu.com   <none>           <none>
vol-emptydir-pod   2/2     Running   0          20m   10.244.3.41   node03.magedu.com   <none>           <none>
vol-nfs-pod        1/1     Running   0          4s    10.244.2.19   node02.magedu.com   <none>           <none>


[root@master chapter7]# kubectl describe pods -n vol vol-nfs-pod
Containers:
  redis:
    Container ID:   docker://cde1e329eb01ecceb05a4cd297ec54f0004cf67c5527ebb5349f0bcc9687cfe0
    Image:          redis:alpine
    Image ID:       docker-pullable://redis@sha256:2cd821f730b90a197816252972c2472e3d1fad3c42f052580bc958d3ad641f96
    Port:           6379/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Thu, 28 Jan 2021 11:32:41 +0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
    	# 挂载/data/至redisdata卷 可写
      /data from redisdata (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rwpm5 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  redisdata: # 卷
    Type:      NFS (an NFS mount that lasts the lifetime of a pod)
    Server:    172.16.1.104
    Path:      /vols/1
    ReadOnly:  false # 可写卷
  default-token-rwpm5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-rwpm5
    Optional:    false
QoS Class:       BestEffort


```

pod生成数据

```bash
[root@master chapter7]# kubectl exec -it vol-nfs-pod -n vol -- sh
/data # redis-cli 
127.0.0.1:6379> SET mykey "www.magedu.com"
OK
127.0.0.1:6379> BGSAVE
Background saving started
127.0.0.1:6379> 
/data # ls /data/
dump.rdb
```

重载pod, 至node1

```diff
[root@master chapter7]# cat vol-nfs.yaml
apiVersion: v1
kind: Pod
metadata:
  name: vol-nfs-pod
  namespace: vol
  labels:
    app: redis
spec:
+ nodeName: node01.magedu.com
  containers:
  - name: redis # redis
    image: redis:alpine
    ports:
    - containerPort: 6379
      name: redisport # redis端口为redisport
    volumeMounts: # 挂载redisdata卷名
    - mountPath: /data # redis镜像，默认snapshot持久路径在/data
      name: redisdata
  volumes:
    - name: redisdata # 定义卷名
      nfs:
        server: 172.16.1.104 # server
        path: /vols/1

```

```bash
[root@master chapter7]# kubectl get pod -n vol -o wide
NAME               READY   STATUS    RESTARTS   AGE   IP            NODE                NOMINATED NODE   READINESS GATES
myapp              1/1     Running   0          97m   10.244.1.15   node01.magedu.com   <none>           <none>
vol-emptydir-pod   2/2     Running   0          25m   10.244.3.41   node03.magedu.com   <none>           <none>
																	# 在node01
vol-nfs-pod        1/1     Running   0          24s   10.244.1.16   node01.magedu.com   <none>           <none>


# 数据还在
[root@master chapter7]# kubectl exec -it vol-nfs-pod -n vol -- sh
/data # redis-cli
127.0.0.1:6379> GET mykey
"www.magedu.com"
127.0.0.1:6379> 
/data # ls
dump.rdb

```

验证nfs server

```bash
[root@node04 ~]# ls /vols/1
dump.rdb
[root@node04 ~]# 
```





# PV/PVC

你使用pod的存储卷时，就得你得学习存储怎么连接，有背于k8s的**生产、消费模型**。**k8s只需要多大空间，不关心存储从哪儿来，用户只需要消费。这就需要用到PV/PVC**



一个nfs目录对应一个pv, pv并非一一对应一个存储系统。

nfs -> 路径

rdb -> image

aws -> 云盘



- 资源级别
  - 名称空间：pod,PVC
  - 集群级别：pv

名称空间中使用PV, 需要PV注册到名称空间

PV只能被引用一次，由**pvc**请求占用PV

myns的PVC占用PV1(binding), 其他名称名称空间的PVC不能引用这个PV1了。

Pod通过PVC来使用PV



```bash
[root@master chapter7]# kubectl explain pods.spec.volumes.persistentVolumeClaim
KIND:     Pod
VERSION:  v1

RESOURCE: persistentVolumeClaim <Object>

DESCRIPTION:
     PersistentVolumeClaimVolumeSource represents a reference to a
     PersistentVolumeClaim in the same namespace. More info:
     https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims

     PersistentVolumeClaimVolumeSource references the user's PVC in the same
     namespace. This volume finds the bound PV and mounts that volume for the
     pod. A PersistentVolumeClaimVolumeSource is, essentially, a wrapper around
     another type of volume that is owned by someone else (the system).

FIELDS:
   claimName	<string> -required-
     ClaimName is the name of a PersistentVolumeClaim in the same namespace as
     the pod using this volume. More info:
     https://kubernetes.io/docs/concepts/storage/persistent-volumes#persistentvolumeclaims

   readOnly	<boolean>
     Will force the ReadOnly setting in VolumeMounts. Default false.

```

删除Pod, pvc不会被删除。可以手动删除PVC, PVC删除了，是否删除PV(回收PV策略：delete回收空间删除PV，retain不删除PV)?  删除了PV相当于删除了数据。 

多个Pod，可以同时引用相同的PVC->nfs pv。pvc能否多路读写？由pv定义时指定。

PVC特性应该是PV特性的子集。PV特性应该是底层存储特性的子集。



## PV状态

pv从哪儿来(provisioning)？

​	支持成为PV的类型 https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes

- *静态供给*：管理员定义PV 

- *动态供给*：

  - **存储自身支持** 支持动态供给的类型 https://kubernetes.io/docs/concepts/storage/persistent-volumes/#expanding-persistent-volumes-claims
  - **存储类**(sc, storageclass) 创建pvc后，pvc请求sc，sc自动连接存储系统的api, 自动创建pv。
    - pvc属于存储类，只能绑定属于SC的PV。
    - PVC不属于存储类，只能绑定不属于SC的PV。

  

pv创建后的状态？

- binding： pvc已经绑定了pv
- available: PV可用



pv 回收策略（Reclaiming）?

- delete: 删除pvc, 自动删除pv.
- retain: 删除pvc, 不删除pv.



存储设备不在K8S之上，而是在K8S之外。使用存储，要么配置PV要么配置SC。

存储管理员定义PV或SC。

用户直接调用PVC来绑定。



```bash
# 准备存储空间
#将/vols/v2创建为pv
# pv不属于名称空间，不需要定义名称空间
[root@master chapter7]# kubectl explain pv.spec. | grep '>'
RESOURCE: spec <Object>
   accessModes	<[]string> # 访问模型
   		https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes

   awsElasticBlockStore	<Object>
   azureDisk	<Object>
   azureFile	<Object>
   capacity	<map[string]string>
   cephfs	<Object>
   cinder	<Object>
   claimRef	<Object>
   csi	<Object>
   fc	<Object>
   flexVolume	<Object>
   flocker	<Object>
   gcePersistentDisk	<Object>
   glusterfs	<Object>
   hostPath	<Object>
   iscsi	<Object>
   local	<Object>
   mountOptions	<[]string>
   nfs	<Object>
   nodeAffinity	<Object>
   persistentVolumeReclaimPolicy	<string>
   photonPersistentDisk	<Object>
   portworxVolume	<Object>
   quobyte	<Object>
   rbd	<Object>
   scaleIO	<Object>
   storageClassName	<string>
   storageos	<Object>
   volumeMode	<string>
   vsphereVolume	<Object>

```

> 并非所有存储能定义为PV

https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes

The access modes are:

- ReadWriteOnce -- 单路读写，RWO
- ReadOnlyMany -- 多路只读, ROX
- ReadWriteMany --多路读写, RWX



## 静态供给pv



```diff
[root@master chapter7]# cat pv-nfs-0001.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-nfs-2
  # 注意不使用名称空间
  labels:
    storsys: nfs
    release: stable
spec:
+  capacity:      # 存储容量
+    storage: 5Gi # 大小，不定义, 取决于底层存储空间大小
+  volumeMode: Filesystem # 访问存储设备的接口: 块接口或文件系统接口
+  accessModes: # 访问模型
+    - ReadWriteOnce # 1路读写 
+    - ReadWriteMany # 多路读写
+    - ReadOnlyMany  # 多路只读
+  persistentVolumeReclaimPolicy: Retain     # 回收策略，删除pvc, pv怎么办
+  #storageClassName: slow # 存储类
+  mountOptions:  # pvc的选项。pv挂载到容器时，关联的选项; 需要才定义。
    - hard
    - nfsvers=4.1
+  nfs: # 存储系统的特性
    path:  "/vols/2"  # 
    server: 172.16.1.104

```



```bash
[root@master chapter7]# kubectl apply -f pv-nfs-0001.yaml 
persistentvolume/pv-nfs-2 created
[root@master chapter7]# kubectl get pv
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
									# 回收策略          # 当前状态
pv-nfs-2   5Gi        RWO,ROX,RWX    Retain           Available                                   7s

```

定义pvc

```diff
"pvc-nfs-0001.yaml" 15L, 264C                                                                                                                                                                                                                                                                            1,1           All
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: redis-data
+  namespace: vol
spec:
+  accessModes: # 模型
+    - ReadWriteOnce
+  volumeMode: Filesystem # 接口
  resources:
+    requests:  # 请求资源需求大小; pv可能有10Gi, 50Gi, 只需要最佳的PV
+      storage: 3Gi
  #storageClassName: slow
+  selector:    # 标签选择器，选择PV
    matchLabels:
      storsys: nfs
      release: stable

```

pvc创建后有状态

```bash
[root@master chapter7]# kubectl apply -f pvc-nfs-0001.yaml 
persistentvolumeclaim/redis-data created
[root@master chapter7]# kubectl get pvc -n vol
NAME         STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
											# 定义的单路读写，但是PV特性多种，会全部显示
redis-data   Bound    pv-nfs-2   5Gi        RWO,ROX,RWX                   7s
```

查看pv状态

```bash
[root@master chapter7]# kubectl get pv -n vol
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM            STORAGECLASS   REASON   AGE
												      #绑定    #vol名称空间下的pvc为redis-data
pv-nfs-2   5Gi        RWO,ROX,RWX    Retain           Bound    vol/redis-data                           5m21s
```



创建pod，使用此pvc绑定的pv

```diff
[root@master volumes]# cat vol-demo-redis.yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    app: redis-dmeo       # app标签方便deploy/svc引用
  name: redis-demo
+  namespace: vol
spec:
  volumes:
  - name: redis-data
+    persistentVolumeClaim:       # Pod请求使用vol名称空间中的PVC redis-data,
+      claimName: redis-data
  containers:
  - image: redis:alpine
    name: redis
    resources: {}
    volumeMounts: # kubectl explain pod.spec.containers.volumeMounts
+    - name: redis-data             # 容器挂载PVC至/data
+      mountPath: /data
  dnsPolicy: ClusterFirst
  restartPolicy: Always      #  重启策略, onfailure exit !0, 重启。     Always停了就重启

```

```bash
[root@master volumes]# kubectl apply -f vol-demo-redis.yaml
kubepod/redis-demo created
[root@master volumes]# kubectl describe pods redis-demo -n vol
Node:         node02.magedu.com/172.16.1.102 # 运行的节点
Containers:
  redis:
    Container ID:   docker://fa8819abe2eabe1ae2a22a512901a44824a5ed6801392c5d446ae2e7b074d9fc
    Image:          redis:alpine
    Image ID:       docker-pullable://redis@sha256:2cd821f730b90a197816252972c2472e3d1fad3c42f052580bc958d3ad641f96
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Thu, 28 Jan 2021 13:54:10 +0800
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
    	#挂载卷至/data
      /data from redis-data (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rwpm5 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  redis-data: # 存储卷PVC
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  redis-data # 请求绑定 同一名称空间下的PVC redis-data
    ReadOnly:   false # 读写
  default-token-rwpm5:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-rwpm5
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
```

测试生成数据

```bash
[root@master volumes]# kubectl exec -it redis-demo -n vol -- sh
/data # redis-cli
127.0.0.1:6379> KEYS *
(empty array)
127.0.0.1:6379> SET hikey "www.ilinux.io"
OK
127.0.0.1:6379> BGSAVE
Background saving started
127.0.0.1:6379> 
/data # ls 
dump.rdb
/data # 

# nfs server验证
[root@node04 ~]# ls /vols/2
dump.rdb

```

此时删除pod, 重建pod

```bash
kubectl delete -f vol-demo-redis.yaml 
```

有意的将pod运行节点固定在其他节点，验证数据

```diff
"vol-demo-redis.yaml" 21L, 548C                                                                                                 
apiVersion: v1
kind: Pod
metadata:
  labels:
    app: redis-dmeo       # app标签方便deploy/svc引用
  name: redis-demo
  namespace: vol
spec:
+  nodeName: node01.magedu.com
  volumes:
  - name: redis-data
    persistentVolumeClaim:
      claimName: redis-data
  containers:
  - image: redis:alpine
    name: redis
    resources: {}
    volumeMounts: # kubectl explain pod.spec.containers.volumeMounts
    - name: redis-data
      mountPath: /data
  dnsPolicy: ClusterFirst
  restartPolicy: Always      #  重启策略, onfailure exit !0, 重启。     Always停了就重启

```

```bash
[root@master volumes]# kubectl apply -f vol-demo-redis.yaml 

[root@master volumes]# kubectl get pod -n vol -o wide
NAME               READY   STATUS    RESTARTS   AGE    IP            NODE                NOMINATED NODE   READINESS GATES
myapp              1/1     Running   0          4h3m   10.244.1.15   node01.magedu.com   <none>           <none>
																	 # 运行在node01
redis-demo         1/1     Running   0          12s    10.244.1.17   node01.magedu.com   <none>           <none>


# 验证数据，还存在
[root@master volumes]# kubectl exec -it redis-demo -n vol -- sh
/data # redis-cli 
127.0.0.1:6379> KEYS *
1) "hikey"

```

明显感觉到只需要定义PVC, 调用PVC， 不需要关心存储底层的细节



## pvc保护策略

k8s v1.11之前, pvc被使用可以删除。之后版本，pvc被使用不能真正删除，直到Pod删除时才可以删除PVC。

```bash
[root@master volumes]# kubectl get pvc -n vol
NAME         STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
redis-data   Bound    pv-nfs-2   5Gi        RWO,ROX,RWX                   36m
[root@master volumes]# kubectl delete pvc -n vol redis-data
persistentvolumeclaim "redis-data" deleted
^[[A


^C
[root@master volumes]# kubectl get pvc -n vol
NAME         STATUS        VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
redis-data   Terminating   pv-nfs-2   5Gi        RWO,ROX,RWX                   38m

[root@master volumes]# kubectl delete pod -n vol redis-demo
pod "redis-demo" deleted

```

PVC删除了，PV怎么办？取决于PV定义的回收策略

```bash
[root@master volumes]# kubectl get pvc -n vol
No resources found in vol namespace.
# 现在pvc已经删除


# 但是pv我们定义的Retain表示PVC删除后，还保留
[root@master volumes]# kubectl get pv
NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM            STORAGECLASS   REASON   AGE
													  # 释放
pv-nfs-2   5Gi        RWO,ROX,RWX    Retain           Released   vol/redis-data                           44m
```

PV怎么再次使用

- 删除PV
- 手工回收

```bash
# 删除
[root@master volumes]# kubectl delete pv/pv-nfs-2
persistentvolume "pv-nfs-2" deleted

# 验证数据
[root@node04 ~]# ls /vols/2
dump.rdb

```



真正好腾空间，需要清理存储服务器上的数据

```bash
[root@node04 ~]# rm -f /vols/2/*
```

## 存储类

按存储设备功能分类

aws/azure 归为云存储 cloud

nfs 归为slow



使用了存储类，用户定义pvc时仅需要调用存储类。

存储类的PV：

- 静态定义PV
- 动态供给PV



```bash
[root@master volumes]# kubectl explain sc | grep '>'
   allowVolumeExpansion	<boolean> # 支持拉伸ceph
   allowedTopologies	<[]Object>
   apiVersion	<string>
   kind	<string>
   metadata	<Object>
   mountOptions	<[]string>
   parameters	<map[string]string> # 对接外部存储的参数 
   provisioner	<string> -required- # 供给方
   reclaimPolicy	<string> # 类中所有pv的回收策略
   volumeBindingMode	<string> # 访问模型

```

https://kubernetes.io/zh/docs/concepts/storage/storage-classes/

```bash
# 连接glusterfs
[root@master chapter7]# cat glusterfs-storageclass.yaml 
kind: StorageClass
apiVersion: storage.k8s.io/v1beta1
metadata:
  name: gluster-dynamic         # 存储类名
provisioner: kubernetes.io/glusterfs # 存储设备名
parameters: # 连接设备的参数
  resturl: "http://172.16.2.36:8080" 
  restauthenabled: "false"

# 连接ceph
[root@master chapter7]# cat ceph-secret-storageclass.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: ceph-secret
  namespace: kube-system
type: kubernetes.io/rbd
data:
  key: QVFBTEhLRmF0MDdxQ2hBQWY4RFF6N3VFYVJlTFZUQTBJSndQeWc9PQo= 

apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: slow
provisioner: kubernetes.io/glusterfs
parameters:
  resturl: "http://127.0.0.1:8081"
  clusterid: "630372ccdc720a92c681fb928f27b53f"
  restauthenabled: "true"
  restuser: "admin"
  secretNamespace: "default"
  secretName: "heketi-secret"
  gidMin: "40000"
  gidMax: "50000"
  volumetype: "replicate:3"
  
  
# nfs不支持，需要第3方项目
https://github.com/kubernetes-retired/external-storage/tree/master/nfs
```















