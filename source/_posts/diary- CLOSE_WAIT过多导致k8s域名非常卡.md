---
title: k8s域名非常卡
date: 2021-06-22 09:51:27
tags:
- 个人日记
---

# cpu/ram
<!--more-->

ingress 正常

后端pod正常

# 排查流程

## 本地网速

异常：其他主机正常，说明是网络问题

正常：50Mb, 其他云主机，也异常。向下排查

## ingress curl后端ip

异常：

## 后端pod

进入后查看连接数

```bash
netstat -n  | awk '{++S[$NF]}END {for (i in S) {print i,S[i]}}'
CLOSE_WAIT 3000
ESTABLISHED 1000
```

 删除Pod, 重建后恢复



# close_wait过多分析

https://blog.csdn.net/ruixj/article/details/1871979

## 调整内核参数

> close_wait过多原因及解决方法

```bash
# https://www.programmersought.com/article/74221875444
net.ipv4.tcp_keepalive_time   = 600
net.ipv4.tcp_keepalive_probes = 2
net.ipv4.tcp_keepalive_intvl  = 2
```

## 查看close_wait相关的ip

```bash
root@saasapi-prod-deploy-84f78d69bb-8fbns:~# netstat -n | grep CLOSE_WAIT | awk '{split($5,a,":"); ++S[a[1]]}END {for (i in S) {print i, S[i]}}'
118.31.232.166 11164
xxx...
```

> 这个ip属于阿里云，排查业务与阿里云的业务。我们去新POD上，模拟请求业务API, 发现新POD的CLOSE_WAIT一直上升。
>
> 从以下图可以看出，因为我们请求阿里云之后，我们不会关闭连接。
>
> 之后阿里云关了连接，我们进入CLOSE_WAIT状态，一直不关连接，就出现这个问题。

```bash
上面我碰到的这个问题主要因为TCP的结束流程未走完，造成连接未释放。现设客户端主动断开连接，流程如下

 

       Client                            消息                                    Server

         close()
                                      ------ FIN ------->
        FIN_WAIT1                                                               CLOSE_WAIT
                                      <----- ACK -------
        FIN_WAIT2 
                                                                                  close()
                                       <------ FIN ------                     
        TIME_WAIT                                                                LAST_ACK      

                                      ------ ACK ------->  
                                                                                   CLOSED
           CLOSED
           
# 此图，是连接连接后，关闭时使用的图。
# 上面的client可能是真正的客户端，也可能是服务器自身。
# 总会有一方会关闭连接的。
```

## 联系开发，获取访问阿里云的curl命令

通过go压力测试工具，

```bash
[gjpyun@iZbp1a57bbyiw0o0fnnxtqZ ~]$ ./go-stress-testing-linux -c 10 -n 1000 -p ./a.txt 
# A.TXT保存了curl命令
```

之后发现，在请求过程中, 出现一个现象

> 建立连接一直长，并发测试完了，建立连接还在。
>
> 如上图，等阿里云close()给我们关连接之后，我们进入CLOSE_WAIT状态，但是我们没有close(),close_wait状态一直变多，所以就导致这个问题。

```bash
root@saasapi-prod-deploy-84f78d69bb-8fbns:~# cat abc.sh 
netstat -n | awk '{++S[$NF]}END {for (i in S) {print i, S[i]}}'
root@saasapi-prod-deploy-84f78d69bb-8fbns:~# watch -n1 'bash abc.sh'
CLOSE_WAIT 11164
TIME_WAIT 35
ESTABLISHED 24
State 1
```

等close_wait达到1万时，并发

```bash
[gjpyun@iZbp1a57bbyiw0o0fnnxtqZ ~]$ ./go-stress-testing-linux -c 50 -n 1000 -p ./a.txt 

# 观察到ESTABLISHED如上，只有20-100个，不能建立新的连接。
# 并且出现502
─────┬───────┬───────┬───────┬────────┬────────┬────────┬────────┬────────┬────────┬────────
 耗时│ 并发数│ 成功数│ 失败数│   qps  │最长耗时│最短耗时│平均耗时│下载字节│字节每秒│ 错误码
─────┼───────┼───────┼───────┼────────┼────────┼────────┼────────┼────────┼────────┼────────
   1s│     30│    172│     23│  186.51│  297.42│   48.13│  160.85│        │        │200:172;500:23
   2s│     30│    389│     23│  203.70│  304.64│   48.13│  147.28│        │        │200:389;500:23
   3s│     30│    586│     23│  201.91│  304.64│   48.13│  148.58│        │        │200:586;500:23
   4s│     30│    775│     23│  198.53│  304.64│   48.13│  151.11│        │        │200:775;500:23
   5s│     30│    971│     23│  198.15│  348.29│   48.13│  151.40│        │        │200:971;500:23
   6s│     30│   1171│     23│  198.15│  390.53│   48.13│  151.40│        │        │200:1171;500:23
   7s│     30│   1363│     23│  197.73│  390.53│   48.13│  151.72│        │        │200:1363;500:23
   8s│     30│   1553│     23│  196.19│  390.53│   48.13│  152.91│        │        │200:1553;500:23
   9s│     30│   1742│     23│  196.03│  390.53│   48.13│  153.04│        │        │200:1742;500:23
  10s│     30│   1949│     23│  196.17│  390.53│   48.13│  152.93│        │        │200:1949;500:23
  11s│     30│   2156│     23│  196.90│  390.53│   48.13│  152.36│        │        │200:2156;500:23
  12s│     30│   2361│     23│  197.66│  390.53│   48.13│  151.78│        │        │200:2361;500:23
  13s│     30│   2561│     23│  198.27│  390.53│   48.13│  151.31│        │        │200:2561;500:23
  14s│     30│   2760│     23│  198.45│  390.53│   48.13│  151.17│        │        │200:2760;500:23
  15s│     30│   2967│     23│  198.83│  390.53│   48.13│  150.88│        │        │200:2967;500:23

```

如果把pod重建之后，同样的并发。

```bash
[gjpyun@iZbp1a57bbyiw0o0fnnxtqZ ~]$ ./go-stress-testing-linux -c 50 -n 1000 -p ./a.txt 

# 观察到ESTABLISHED如上，一下可以建立4000-5000个连接，可以处理完所有请求。
  耗时│ 并发数│ 成功数│ 失败数│   qps  │最长耗时│最短耗时│平均耗时│下载字节│字节每秒│ 错误码
─────┼───────┼───────┼───────┼────────┼────────┼────────┼────────┼────────┼────────┼────────
   1s│     50│    188│      0│  207.38│  475.10│   80.25│  241.10│        │        │200:188
   2s│     50│    415│      0│  221.75│  796.36│   69.48│  225.48│        │        │200:415
   3s│     50│    653│      0│  224.60│  796.36│   57.20│  222.62│        │        │200:653
   4s│     50│    876│      0│  227.19│  796.36│   57.20│  220.08│        │        │200:876
   5s│     50│   1110│      0│  228.18│  796.36│   57.20│  219.12│        │        │200:1110
   6s│     50│   1345│      0│  228.96│  796.36│   57.20│  218.37│        │        │200:1345
   7s│     50│   1583│      0│  231.08│  796.36│   57.20│  216.38│        │        │200:1583
   8s│     50│   1822│      0│  231.35│  796.36│   57.20│  216.12│        │        │200:1822

```



## 解决

### 临时

每天晚上用户不使用时，重启一下pod, 会释放连接，就恢复了。

### 开发修改代码。

xxxx 采用静态方法，单实例，就不需要多建立连接了。
