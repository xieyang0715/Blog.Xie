---
title: 网络模型及网络策略
date: 2021-02-02 01:48:24
tags:
---





# 前言

- vxlan 

  - vxlan：2层遂道, 封装mac, 类似lvs-dr模型。**所有模式不可用时，使用此模式。**
  - vxlan+directrouting 2层遂道+2层直接通信。节点IP跨网络自动升级2层遂道；不跨网络使用host-gw；云环境可能不支持。
  - host-gw：vxlan+directrouting的子集，**不直接使用host-gw**。2层通信。 

- calico 支持网络策略

  - ipip 3层遂道。ip封装ip，**性能没有vxlan好**。
  - bgp：机房得支持。 云环境可能不支持。

  

pod属于namespace, 跨名称空间pod, 只要在同k8s环境就可以通信，不安全。

- calico/canal网络策略：跨pod通信隔离
  - networkpolicy
    - ingress  from ->  ports, selector pod
    - egress   selector pod -> to, ports

<!--more-->
# 容器化应用跨节点通信？

有多个节点，应用进程跨节点协作时，应用程序的Ip是节点ip就可以了。

但是容器化运行在网络名称空间中，每个应用程序有独立的IP地址，甚至多个IP地址。两个容器化应用通信，而且k8s运行的pod具体在哪个节点我们也不得而知（只要我们不强制影响调度器结果）



**docker创建默认使用的网络模型：bridge（桥接到docker0）**：容器虚拟桥卡绑定在docker0上。另一个节点上容器也关联到docker0桥上。有可能2个节点上的容器使用了相同的地址，不能通信，而且**bridge中的容器与节点外部通信使用SNAT方式。接点外部不能直接访问节点上的容器，需要DNAT。**

![image-20210202095556556](http://myapp.img.mykernel.cn/image-20210202095556556.png)

> 容器->docker0 ------------------------------------------------------------------------------------------------ docker0 -> 容器

如果K8S也使用docker网络模型，跨节点的pod通信，得有多少个nat需要维护，这么多nat性能也不好。



## k8s网络

- pod网络：**插件提供** 所有pod有自已的网络 k8s:`--cluster-cidr=`  controller, kube-proxy;            flannel: net-conf.json："Network": "10.244.0.0/16",
- service网络：**service资源管理** `pod`与`pod`通信不是直接通信，而是通过`service`, service也有自已的网络 `--service-cluster-ip-range`,api, controller
- 节点网络：**管理员管理**                     flannel通信： docker -> cni0 -> flannel.1 -> **eth0 -> eth0** ->  flannel.1 -> cni0 -> docker

<!--more-->

## pod网络通信

- pod内容器 lo接口
- pod与pod通信，不能跨网络，必须是平面网络
- pod - service. service是iptables/ipvs规则，pod可以直接本机被规则捕获
- 外部客户端 - Pod通信: Nodeport, hostnetwork, hostport, externalname/endpoint

保证这些pod通信，是非常复杂的逻辑，方法如下

### bgp协议

1. 突破私有网络：**[大]二层网络借助BGP协议**  内部容器直接走**物理桥**, 地址分配机制保证所有pod分配地址在同一个网络。（openstack走物理桥，所有物理机在同一个网络）
   - 问题：假如1千个节点，每个节点100个pod, 就10万个pod。广播ARP解析会把内网带宽耗尽。
     - 每个节点做一个VLAN,  同节点走广播。跨接点，VXLAN交换机制。
     - BGP协议，边际网关协议，管理大二层网络。**要求机房支持使用BGP协议**，很多机房不支持BGP。

### overlay协议

1. 不突破私有网络：**overlay或叠加网络**：内部容器直接走**虚拟桥**，两个节点打通遂道，两个pod同网段，本节点内部通信；不同网段，通过物理网卡封装遂道协议报文，送到另一个网卡上。

   >  小轿车打到海南岛，可以不下车，车开到船上，船到对岸，车在开到岛上。这就是遂道。一种机制承载另一种机制

   协议：**vxlan**，实现这个功能。**两个局域网**，通过**二层**隧道协议，让两个局域网互相进行通信（**交换报文**）。注意：2个局域网是一个大网中的两个小子网，其实还是一个小子网 。比如：10.244.0.0/16 B类网划分成256个C网：节点1：10.244.0.0/24 节点2：10.244.1.0/24, 本地通信没有关系。一旦需要跨节点通信时，将24位聚合为16位。

   VXLAN怎么知道目标报文的网段在哪个节点上？

   > 10.244.0.0/24节点上到10.244.1.0/24网络，遂道封装时目标IP怎么知道封装哪个？
   >
   > vxlan会把网络和节点物理网卡地址映射关系记录在一个表中。数据vxlan自已不能保存，需要借助外部存储etcd保存。
   >
   > 因此：10.244.0.0/24节点上到10.244.1.0/24网络，查表得1.0/24网络在局域网2的节点物理网卡IP：192.168.100.101/24地址上（假设），这样就直接封装这个IP为外层的IP，就把报文发送到这个主机。目标节点封装IP后又看到一个首部是10.244.1.0/24网络就可以直接发送给目标容器。
   >
   > 注意：vxlan是2层遂道，即到目标节点使用mac地址不是ip地址，就类似于LVS的DR模型。封装的首部时MAC是封装查询网段对应接口的MAC。
   >
   > 注意：calico的ipip是3层遂道，ip封装ip.

   

   应用场景：叠加网络是较大网络场景中，实现网络虚拟化基础技术之一。而vxlan这种实现，以性能高、协议开放著称于世。

   

   <img src="http://myapp.img.mykernel.cn/image-20210202102842533.png" alt="image-20210202102842533" style="zoom: 67%;" />

# K8S网络模型对比

| 协议    | 网络                     | 性能                                                         | 应用场景                                    |
| ------- | ------------------------ | ------------------------------------------------------------ | ------------------------------------------- |
| BGP     | 大二层网络，需要机房支持 | bgp性能更高，彼此间直接通信。2层直接通信。                   | 需要机房支持BGP协议，公有云环境可能不支持。 |
| overlay | 叠加网络、遂道网络       | vxlan技术有遂道封装，MTU小于默认1500，需要额外添加IP首部，所以承载能力小于BGP直接通信。管理性优于BGP. <br/>2层遂道是封装目标节点的mac. 3层遂道是封装目标节点的ip. **2层遂道更加安全。** | 无限制                                      |

> **flannel host-gw**不是`overlay`也不是`bgp`, 是直接**把网络地址和接口的映射关系转换为路由规则**，直接走路由。但是云计算环境中，直接走路由未必可行。
>
> ```
> default via 192.168.31.1 dev ens33 proto static metric 100 
> 10.244.0.0/24 dev cni0 proto kernel scope link src 10.244.0.1  # 本地网络
> 10.244.1.0/24 via 192.168.31.63 dev ens33  # 其他网络直接走他的IP作为网关
> 10.244.2.0/24 via 192.168.31.61 dev ens33 
> ```







# k8s网络插件

k8s把网络功能(为pod分配网络完成pod网络通信)基于插件接口放那里，交给第三方机构实现，只要遵循接口开发的插件，都可以对接作为K8S网络提供使用。

https://kubernetes.io/zh/docs/concepts/cluster-administration/networking/



主流的calico、falnnel，互联网获得文档flannel居多，官方部署时默认flannel。

k8s 网络插件接口：kubenet（废弃: flannel可以对接）、[CNI](https://kubernetes.io/zh/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#cni)（容器网络接口: flannel可以对接 `--network-plugin=cni`  ，配置文件默认在`--cni-conf-dir` （默认是 `/etc/cni/net.d`），程序文件在：`--cni-bin-dir`（默认是 `/opt/cni/bin`），二进制部署必须配置）



pod虚拟网卡生成三种方式

- OVS/Bridge , 虚拟心态网。veth pair  目前使用的
- macvlan/ipvlan 
- sr-iov



## flannel

https://github.com/coreos/flannel#flannel

轻量、简单易用

缺陷：不支持网络策略、默认vxlan跨节点遂道。

cni对接flannel

```diff
[root@master ~]# ls /opt/cni/bin/
bandwidth  bridge  dhcp  firewall  flannel  host-device  host-local  ipvlan  loopback  macvlan  portmap  ptp  sbr  static  tuning  vlan
+[root@master ~]# cat  /etc/cni/net.d/10-flannel.conflist  # 配置文件 不需要修改，了解即可
{
+  "name": "cbr0", # 桥，名字是cni0. 另一个遂道接口桥flannel.1
  "cniVersion": "0.3.1",
  "plugins": [
    {
      "type": "flannel", # flannel
      "delegate": {
        "hairpinMode": true,
        "isDefaultGateway": true
      }
    },
    {
      "type": "portmap",
      "capabilities": {
        "portMappings": true
      }
    }
  ]
}


+# 查看桥
[root@master ~]# ifconfig
+cni0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450 
+        inet 10.244.0.1  netmask 255.255.255.0  broadcast 10.244.0.255 # pod关联至这个桥，所以网段是10.244.0.0/24
        inet6 fe80::4096:f3ff:fed9:b298  prefixlen 64  scopeid 0x20<link>
        ether 42:96:f3:d9:b2:98  txqueuelen 1000  (Ethernet)
        RX packets 2389726  bytes 193548550 (184.5 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 2439415  bytes 216536201 (206.5 MiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

docker0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500
        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
        ether 02:42:84:2d:dd:bc  txqueuelen 0  (Ethernet)
        RX packets 0  bytes 0 (0.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 0  bytes 0 (0.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 172.16.1.100  netmask 255.255.0.0  broadcast 172.16.255.255
        inet6 fe80::5054:ff:fee8:ee2e  prefixlen 64  scopeid 0x20<link>
        ether 52:54:00:e8:ee:2e  txqueuelen 1000  (Ethernet)
        RX packets 6483643  bytes 1126406189 (1.0 GiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 6764342  bytes 3861433851 (3.5 GiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

+flannel.1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1450 # pod -> cni0 -> 内核级路由 -> flannel.1
        inet 10.244.0.0  netmask 255.255.255.255  broadcast 10.244.0.0 
        inet6 fe80::f8fa:a5ff:fe22:bd4d  prefixlen 64  scopeid 0x20<link>
        ether fa:fa:a5:22:bd:4d  txqueuelen 0  (Ethernet)
        RX packets 6575  bytes 600807 (586.7 KiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 6700  bytes 1029899 (1005.7 KiB)
        TX errors 0  dropped 8 overruns 0  carrier 0  collisions 0


[root@master ~]# brctl show
bridge name	bridge id		STP enabled	interfaces
+cni0		8000.4296f3d9b298	no		veth2766e6f2 # pod关联至此桥
										veth75de26e0 
+docker0		8000.0242842dddbc	no		             # k8s并未使用


+#路由表
[root@master ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         172.16.0.1      0.0.0.0         UG    0      0        0 eth0
+10.244.0.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0 # 本机cni0
+#非本机，全部走flannel.1
+10.244.1.0      10.244.1.0      255.255.255.0   UG    0      0        0 flannel.1
+10.244.2.0      10.244.2.0      255.255.255.0   UG    0      0        0 flannel.1
+10.244.3.0      10.244.3.0      255.255.255.0   UG    0      0        0 flannel.1

+#flannel.1添加2层遂道首部，走物理网卡 -> 另一个节点
```

### flannel工作逻辑

![image-20210202135705283](http://myapp.img.mykernel.cn/image-20210202135705283.png)

> container1 -> cni0 -非本机-> flannel.1(route -n ) -遂道协议Vxlan/udp/host-gw封装-> eth0 -> eth0 -> flannel.1 - 遂道协议Vxlan/udp/host-gw解封装-> cni0 -> container3
>
> backend: 跨节点报文转发方式，也backend
>
> backend3种方式
>
> udp: 4层遂道，性能更差。设计最初使用udp, 内核不支持vxlan。世人都认为flannel性能差
>
> vxlan: 2层遂道。
>
> host-gw: 动态路由

 ### flannel配置清单

For Kubernetes v1.17+ `kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml`



每个节点均有一个flannel

```diff
kind: DaemonSet
```

有几个节点即有几个flannel

```bash
[root@node01 ~]# kubectl get po -n kube-system -L app -l app=flannel -o wide
NAME                    READY   STATUS    RESTARTS   AGE   IP             NODE                NOMINATED NODE   READINESS GATES   APP
															# 同节点IP，说明flannel共享节点网络名称空间，可以直接创建cni0接口，相当于运行系统级守护进程
kube-flannel-ds-2s6p8   1/1     Running   0          18d   172.16.1.102   node02.magedu.com   <none>           <none>            flannel
kube-flannel-ds-4l4hp   1/1     Running   0          18d   172.16.1.100   master.magedu.com   <none>           <none>            flannel
kube-flannel-ds-qqrw2   1/1     Running   0          18d   172.16.1.101   node01.magedu.com   <none>           <none>            flannel
kube-flannel-ds-vbw8m   1/1     Running   0          18d   172.16.1.103   node03.magedu.com   <none>           <none>            flannel


[root@node01 ~]# kubectl get node 
NAME                STATUS   ROLES                  AGE   VERSION
master.magedu.com   Ready    control-plane,master   18d   v1.20.2
node01.magedu.com   Ready    <none>                 18d   v1.20.2
node02.magedu.com   Ready    <none>                 18d   v1.20.2
node03.magedu.com   Ready    <none>                 18d   v1.20.2
```

> 部署flannel
>
> systemd: flannel, 升级难：rpm升级、修改配置、重载
>
> pod: flannel, 方便升级，apply一下



配置信息

```diff
[root@node01 ~]#  kubectl get cm kube-flannel-cfg -n kube-system -o yaml
apiVersion: v1
data:
+  cni-conf.json: | # /etc/cni/cni.d/fllanel配置
    {
      "name": "cbr0",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
+  net-conf.json: | # flannel的backend的配置，工作类型
    {
+      "Network": "10.244.0.0/16", # 部署k8s网络必须一样。kubeadm: --pod-network-cidr 二进制部署：--cluster-cidr=  controller, kube-proxy
      "Backend": {
+        "Type": "vxlan" # 2层遂道
      }
    }
+kind: ConfigMap # 配置信息
name: kube-flannel-cfg
namespace: kube-system

```

### flannel使用etcd保存信息

- 专用etcd

- 共享k8s的etcd，万一访问清理了etcd咋办？flannel通过api server访问etcd.

  > 从flannel的 clusterrolebinding绑定的clusterrole use  PodSecurityPolicy和查看pod/node/node/status权限。暂时看不出有啥etcd操作的权限。
  >
  > 北京-Arvin: 现在是kubelet调用CNI，由CNI再调用网络插件二进制文件flannel创建并初始化network ns给pod，全程网络插件不和etcd打交道

 

### flannel测试遂道协议

2个节点2个pod, ping抓包

```bash
#清理默认名称空间所有pod

[root@master ~]# kubectl create deploy   test-flannel --image=ikubernetes/myapp:v1 --port=80 --replicas=2 --save-config=true

[root@master ~]# kubectl get pod -o wide -l app=test-flannel
NAME                            READY   STATUS    RESTARTS   AGE   IP            NODE                NOMINATED NODE   READINESS GATES
test-flannel-755db4d67f-2jm2d   1/1     Running   0          9s    10.244.3.60   node03.magedu.com   <none>           <none>
test-flannel-755db4d67f-ck89n   1/1     Running   0          9s    10.244.1.25   node01.magedu.com   <none>           <none>

```

节点1ping节点2

```bash
[root@master ~]# kubectl exec -it test-flannel-755db4d67f-ck89n -- sh
/ # ping 10.244.3.60
PING 10.244.3.60 (10.244.3.60): 56 data bytes
64 bytes from 10.244.3.60: seq=0 ttl=62 time=1.284 ms
64 bytes from 10.244.3.60: seq=1 ttl=62 time=1.278 ms

```

在pod运行的节点抓包 node01.magedu.com

```diff
+# pod - cni0 - flannel.1 - eth0
+#cni0
[root@node01 ~]# tcpdump -i cni0 -nn -vv icmp
tcpdump: listening on cni0, link-type EN10MB (Ethernet), capture size 262144 bytes
15:17:56.496092 IP (tos 0x0, ttl 64, id 29785, offset 0, flags [DF], proto ICMP (1), length 84)
+    10.244.1.25 > 10.244.3.60: ICMP echo request, id 4096, seq 45, length 64 # ping 3.60
15:17:56.497030 IP (tos 0x0, ttl 62, id 44300, offset 0, flags [none], proto ICMP (1), length 84)
    10.244.3.60 > 10.244.1.25: ICMP echo reply, id 4096, seq 45, length 64
15:17:57.496535 IP (tos 0x0, ttl 64, id 30596, offset 0, flags [DF], proto ICMP (1), length 84)


+#flannel.1
[root@node01 ~]# tcpdump -i flannel.1 -nn -vv icmp
tcpdump: listening on flannel.1, link-type EN10MB (Ethernet), capture size 262144 bytes
15:18:53.522373 IP (tos 0x0, ttl 63, id 57432, offset 0, flags [DF], proto ICMP (1), length 84)
+    10.244.1.25 > 10.244.3.60: ICMP echo request, id 4096, seq 102, length 64 # 因为走内核路由走flannel.1
15:18:53.523369 IP (tos 0x0, ttl 63, id 8523, offset 0, flags [none], proto ICMP (1), length 84)
    10.244.3.60 > 10.244.1.25: ICMP echo reply, id 4096, seq 102, length 64
15:18:54.522849 IP (tos 0x0, ttl 63, id 57753, offset 0, flags [DF], proto ICMP (1), length 84)

+#eth0 遂道封装后是到达node03.magedu.com
[root@node01 ~]# tcpdump -i eth0 -nn -vv host 172.16.1.103
tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
15:20:19.564596 IP (tos 0x0, ttl 64, id 59778, offset 0, flags [none], proto UDP (17), length 134)
+    172.16.1.101.46732 > 172.16.1.103.8472: [no cksum] OTV, flags [I] (0x08), overlay 0, instance 1 # 注意OTV报文
IP (tos 0x0, ttl 63, id 32513, offset 0, flags [DF], proto ICMP (1), length 84)
+    10.244.1.25 > 10.244.3.60: ICMP echo request, id 4096, seq 188, length 64    # 请求的ip封装ip

+15:20:19.565392 IP (tos 0x0, ttl 64, id 59216, offset 0, flags [none], proto UDP (17), length 134)
    172.16.1.103.57010 > 172.16.1.101.8472: [no cksum] OTV, flags [I] (0x08), overlay 0, instance 1
IP (tos 0x0, ttl 63, id 50874, offset 0, flags [none], proto ICMP (1), length 84)
+    10.244.3.60 > 10.244.1.25: ICMP echo reply, id 4096, seq 188, length 64 # 回复的ip封装ip
```



### backend

github项目主页的backends

https://github.com/coreos/flannel

https://github.com/coreos/flannel/blob/master/Documentation/backends.md

对于希望提高性能并支持其基础设施(通常不能在云环境中使用)的更有经验的用户，推荐使用HOST-GW。UDP只用于调试，或者用于不支持VXLAN的非常老的内核。

#### VXLAN

使用内核内VXLAN封装数据包.

类型和选项：

- `Type`(字符串)：`vxlan`
- `VNI`(编号)：要使用的VXLAN标识符(VNI)。在Linux上，默认为1.Windows上应该大于或等于4096。
- `Port`(编号)：UDP端口用于发送封装的数据包。在Linux上，默认为内核默认值(目前为8472)，但在Windows上必须为4789。
- `GBP`(布尔)：启用[基于VXLAN组的策略](https://github.com/torvalds/linux/commit/3511494ce2f3d3b77544c79b87511a4ddb61dc89)。默认为`false`。Windows不支持GBP
- `DirectRouting`(布尔值)：启用直接路由(如`host-gw`)当主机位于同一子网时。VXLAN只用于将数据包封装到不同子网上的主机。默认为`false`。Windows不支持DirectRouting。
- `MacPrefix`(字符串)：只在Windows上使用，设置为MAC前缀。默认为`0E-2A`.

```diff
# 生产环境不要进行以下操作


##以下完成flannel切换vxlan + DirectRouting
[root@node01 ~]# kubectl get cm -n kube-system
NAME                                 DATA   AGE
kube-flannel-cfg                     2      18d


[root@node01 ~]# kubectl edit cm -n kube-system kube-flannel-cfg
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "vxlan",
+        "DirectRouting": true
...

#生效配置
[root@node01 ~]# kubectl delete pod -n kube-system -l app=flannel
[root@node01 ~]# kubectl get pod -n kube-system -l app=flannel -o wide
NAME                    READY   STATUS        RESTARTS   AGE   IP             NODE                NOMINATED NODE   READINESS GATES
kube-flannel-ds-2s6p8   0/1     Terminating   0          18d   172.16.1.102   node02.magedu.com   <none>           <none>
kube-flannel-ds-qqrw2   0/1     Terminating   0          18d   172.16.1.101   node01.magedu.com   <none>           <none>
+kube-flannel-ds-rnmsp   1/1     Running       0          12s   172.16.1.100   master.magedu.com   <none>           <none>
kube-flannel-ds-vbw8m   0/1     Terminating   0          18d   172.16.1.103   node03.magedu.com   <none>           <none>

+#查看路由, 所以均走eth0, 不封装
[root@node01 ~]# route -n
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         172.16.0.1      0.0.0.0         UG    0      0        0 eth0
10.244.0.0      172.16.1.100    255.255.255.0   UG    0      0        0 eth0
10.244.1.0      0.0.0.0         255.255.255.0   U     0      0        0 cni0
10.244.2.0      172.16.1.102    255.255.255.0   UG    0      0        0 eth0
10.244.3.0      172.16.1.103    255.255.255.0   UG    0      0        0 eth0
169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0
172.16.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0


+#再次抓包目标节点
[root@master ~]# kubectl exec -it test-flannel-755db4d67f-ck89n -- sh
/ # ping 10.244.3.60

[root@node01 ~]# tcpdump -i eth0 -nn -vv icmp
tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
15:32:54.483683 IP (tos 0x0, ttl 63, id 8921, offset 0, flags [DF], proto ICMP (1), length 84)
+    10.244.3.60 > 10.244.1.25: ICMP echo reply, id 4352, seq 42, length 64 # 没有遂道封装
15:32:55.484170 IP (tos 0x0, ttl 63, id 8980, offset 0, flags [DF], proto ICMP (1), length 84)
    10.244.1.25 > 10.244.3.60: ICMP echo request, id 4352, seq 43, length 64
15:32:55.484965 IP (tos 0x0, ttl 63, id 61134, offset 0, flags [none], proto ICMP (1), length 84)

+#如果节点当前的IP隔离路由器，就会自动升级为vxlan
```



#### host-gw

使用主机GW通过远程机器IP创建到子网的IP路由。需要在运行法兰绒的主机之间直接连接第2层。

host-gw提供了良好的性能，几乎没有依赖，而且易于设置。

类型：

- `Type`(字符串)：`host-gw`

#### UDP

如果您的网络和内核阻止您使用VXLAN或host-GW，则只在调试时使用UDP。

类型和选项：

- `Type`(字符串)：`udp`
- `Port`(编号)：UDP端口用于发送封装的数据包。默认为8285。

### 部署使用flannel

```bash
kubeadm: --pod-network-cidr 二进制部署：--cluster-cidr=  controller, kube-proxy
```

## calico

https://docs.projectcalico.org/

kubernetes部署：https://docs.projectcalico.org/getting-started/kubernetes/self-managed-onprem/onpremises

启用BGP：https://docs.projectcalico.org/getting-started/kubernetes/installation/config-options

`CALICO_IPV4POOL_IPIP`值为`Never`, 就启动了BGP

支持网络策略



### 部署使用calico

```bash
kubeadm: --pod-network-cidr 二进制部署：--cluster-cidr=  controller, kube-proxy
```



## canal

https://github.com/projectcalico/canal

flannel + calico



## kube-router

网络功能不需要叠加网络，利用内核级特性

https://github.com/cloudnativelabs/kube-router





# 网络策略

## 为什么使用策略？

pod属于namespace, 跨名称空间pod, 只要在同k8s环境就可以通信，不安全。

将k8s集群环境共享给**多个项目、多个团队、多个组织**使用时。跨名称空间的安全隔离，将无从得到保障。k8s引入标准资源类型(**NetworkPolicy, 简称netpol**)，允许用户获得名称空间后，在ns中可以定义pod与pod怎么通信，跨ns的pod间通信。

## NetworkPolicy(netpol)

类比ingress资源，ingress controller引入调度流量关键位置，controller中的程序可以是nginx/envoy/traffic，不同程序中的配置不一样，避免用户学习每一个ingress controller配置文件格式,k8s引入标准资源类型(**Ingress**），遵循ingress格式，定义规则后，可以转换为程序的格式。

network policy也一样，按照格式定义后，可以转换为对应系统(unix: freebsd/openbsd; solaris; linux;)的iptables/ipvs规则。

![image-20210202161318435](http://myapp.img.mykernel.cn/image-20210202161318435.png)

1. 选择pod，来定义策略
   - ns
     - all pod 默认
     - label selector 选择pod
   - ip/net                        集群外的主机
2. 访问策略
   - egress 出站；          选择pod访问别的服务；    **client: 选择pods  ->  server: to,ports** 
   - ingress 入站规则； 访问选择pod的服务；        **client:  from    ->      server: 选择pods的ports**

> iptables也一样，仅定义input,或仅定义output
>
> netpol也一样，可以只定义egress或ingress



由于是标准的k8s资源，可以直接解析格式

```bash
[root@master ~]# kubectl explain netpol | grep '>'
   apiVersion	<string>
   kind	<string>
   metadata	<Object>
   spec	<Object>
[root@master ~]# 


[root@master ~]# kubectl explain netpol.spec | grep '>'
RESOURCE: spec <Object>
   egress	<[]Object>
   ingress	<[]Object>
   podSelector	<Object> -required- # 控制当前名称空间的哪个或哪些pod
   policyTypes	<[]string>     # 同时定义ingress/egress哪个生效？还是同时生效？
       "Ingress", "Egress", or "Ingress,Egress", 默认Ingress

[root@master ~]# kubectl explain netpol.spec.egress | grep '>' # 控制出站流量
RESOURCE: egress <[]Object>
   ports	<[]Object>
   to	<[]Object>
   
[root@master ~]# kubectl explain netpol.spec.ingress | grep '>' # 控制入站量
RESOURCE: ingress <[]Object>
   from	<[]Object>
   ports	<[]Object>



[root@master ~]# kubectl explain netpol.spec.egress.to | grep '>'
RESOURCE: to <[]Object>
   ipBlock	<Object> # 其他不定义，使用当前。
   namespaceSelector	<Object> #名称空间标签选择器
   podSelector	<Object> # pod选择
   
   如果列表3个同时定义，看谁在前，就先满足。
   可能有与关系


```



## 部署网络策略

flannel不支持网络策略，需要结合calico使用

https://docs.projectcalico.org/getting-started/kubernetes/flannel/flannel

选择kubernetes的etcd存储作为calico的存储

https://docs.projectcalico.org/getting-started/kubernetes/flannel/flannel#installing-with-the-kubernetes-api-datastore-recommended

```bash
curl https://docs.projectcalico.org/manifests/canal.yaml -O
```

修改yaml, canal也会配置flannel的配置，应该和flannel配置文件一致

```diff
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "vxlan",
+        "DirectRouting": true
      }
    }
```

初始化完成

```bash
[root@master ~]# kubectl apply -f canal.yaml
[root@master ~]# kubectl get po -n kube-system -l k8s-app=canal -o wide 
NAME          READY   STATUS    RESTARTS   AGE     IP             NODE                NOMINATED NODE   READINESS GATES
			  # 每个pod2个容器
canal-22s55   2/2     Running   0          2m46s   172.16.1.103   node03.magedu.com   <none>           <none>
canal-8vkmj   2/2     Running   0          2m46s   172.16.1.102   node02.magedu.com   <none>           <none>
canal-ptkcm   2/2     Running   0          2m46s   172.16.1.100   master.magedu.com   <none>           <none>
canal-vsl8x   2/2     Running   0          2m46s   172.16.1.101   node01.magedu.com   <none>           <none>
```

## 定义网络策略

1. 选择pod，来定义策略

   - ns
     - all pod 默认
     - label selector 选择pod
   - ip/net                        集群外的主机

2. 访问策略

   - egress 出站；          选择pod访问别的服务；    **client: 选择pods  ->  server: to,ports**
     - to哪个ns所有pod或label selector选择的pod. 
   - ingress 入站规则； 访问选择pod的服务；        **client:  from    ->      server: 选择pods的ports**
     - from来自哪个ns所有pod或label selector选择的pod. 

   

- ports不定义所有端口
- podselector {} 所有pod
- 定义ingress生效，则egress默认允许，不控制。
- ingress规则中定义 ["{}"] 默认允许

将来定义，一个规则包含，以下分为多个规则是为了清晰。





dev, prod名称空间

dev名称空间创建pod

```bash
[root@master ~]# kubectl create ns dev --save-config=true
namespace/dev created
[root@master ~]# kubectl create deployment myapp --image=ikubernetes/myapp:v1 -n dev --save-config=true
deployment.apps/myapp created

[root@master ~]# kubectl get pod -n dev -o wide
NAME                    READY   STATUS    RESTARTS   AGE     IP           NODE                NOMINATED NODE   READINESS GATES
myapp-7d4b7b84b-9kvr6   1/1     Running   0          5m15s   10.244.2.2   node02.magedu.com   <none>           <none>


```

prod创建pod, 作客户端

```bash
kubectl run client-pod --image=busybox --dry-run=client -o yaml > client-pod.yaml
[root@master ~]# cat client-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: client-pod
  name: client-pod
spec:
  containers:
  - image: busybox
    name: client
    imagePullPolicy: IfNotPresent # 没有标签会Always
    resources: {}
    command:
    - /bin/sh
    - -c
    - "sleep 86400"
  dnsPolicy: ClusterFirst
  restartPolicy: Always


[root@master ~]# kubectl create ns prod --save-config=true
namespace/prod created
[root@master ~]# kubectl apply -f client-pod.yaml -n prod
pod/client-pod created

[root@master ~]# kubectl get pod -n prod
NAME         READY   STATUS    RESTARTS   AGE
client-pod   1/1     Running   0          6s

```

现在client访问prod

```bash
[root@master ~]# kubectl exec -it client-pod -n prod --  sh
/ # wget -O - -q 10.244.2.2
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>

```

> 由于跨名称空间没有隔离性，所以需要定义策略

### 定义dev空间所有pod,拒绝所有入站，允许所有出站

未定义任何规则，k8s不匹配到规则，均拒绝。

policyTypes不指定，默认不控制，即允许。

```diff
[root@master ~]# cat Kubernetes_Advanced_Practical/chapter11/deny-all-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
+  namespace: dev # 不加名称空间为了通用
spec:
+  podSelector: {} # 不给选择器，表示当前netpol所在名称空间中所有pod
  policyTypes:
+  - Ingress        # 入站生效  ，出去不控制，默认出站允许
```

```bash
kubectl apply -f Kubernetes_Advanced_Practical/chapter11/deny-all-ingress.yaml

# 获取策略
[root@master ~]# kubectl get netpol -n dev
NAME               POD-SELECTOR   AGE
deny-all-ingress   <none>         12s

# 意义
[root@master ~]# kubectl describe netpol -n dev deny-all-ingress
Name:         deny-all-ingress
Namespace:    dev
Created on:   2021-02-02 16:49:20 +0800 CST
Labels:       <none>
Annotations:  <none>
Spec:
  PodSelector:     <none> (Allowing the specific traffic to all pods in this namespace) # dev名称空间所有pod
  Allowing ingress traffic:
    <none> (Selected pods are isolated for ingress connectivity) # 没有入站定义
  Not affecting egress traffic # 出站不生效
  Policy Types: Ingress # 只控制进入来，出去不控制，默认出站允许
```

跨ns的pod访问myapp：不可访问

```bash
/ # wget -O - -q 10.244.2.2
# 注意是阻塞了
wget: can't connect to remote host (10.244.2.2): Connection timed out
```

同ns的pod间访问

```diff
# 扩展myapp
 kubectl scale deploy/myapp --replicas=2 -n dev
[root@master ~]# kubectl get pod -n dev -o wide
NAME                    READY   STATUS    RESTARTS   AGE   IP           NODE                NOMINATED NODE   READINESS GATES
myapp-7d4b7b84b-9kvr6   1/1     Running   0          15m   10.244.2.2   node02.magedu.com   <none>           <none>
myapp-7d4b7b84b-dwss8   1/1     Running   0          8s    10.244.3.4   node03.magedu.com   <none>           <none>


# 访问3.4
[root@master ~]# kubectl exec -n dev -it myapp-7d4b7b84b-9kvr6 -- sh 
+/ # ping 10.244.3.4
PING 10.244.3.4 (10.244.3.4): 56 data bytes
+#阻塞
```

> 同ns空间彼此应该访问



### 开放dev namespace所有pod访问prod ns所有pod

给prod打标签

```bash
[root@master ~]# kubectl get ns --show-labels
NAME              STATUS   AGE    LABELS
config            Active   5d2h   <none>
default           Active   18d    <none>
dev               Active   26m    <none>
develop           Active   15d    <none>
kube-node-lease   Active   18d    <none>
kube-public       Active   18d    <none>
kube-system       Active   18d    <none>
prod              Active   24m    <none>
[root@master ~]# kubectl label ns/prod name=prod 
namespace/prod labeled
[root@master ~]# kubectl get ns --show-labels
NAME              STATUS   AGE    LABELS
config            Active   5d2h   <none>
default           Active   18d    <none>
dev               Active   26m    <none>
develop           Active   15d    <none>
kube-node-lease   Active   18d    <none>
kube-public       Active   18d    <none>
kube-system       Active   18d    <none>
prod              Active   24m    name=prod

```



```diff
"Kubernetes_Advanced_Practical/chapter11/deny-all-ingress.yaml"
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
  namespace: dev # 不加名称空间为了通用
spec:
  podSelector: {} # 不给选择器，表示当前netpol所在名称空间中所有pod
  policyTypes:
  - Ingress        # 入站生效  ，出去不控制，默认出站允许
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
+  name: dev-allow-ingress-ns-prod
+  namespace: dev
spec:
+  policyTypes:
+  - Ingress
+  podSelector: {}  # 不给选择器，表示当前netpol所在名称空间中所有pod
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
+          name: prod     # 匹配标签为name=prod的名称空间

```

```diff
[root@master ~]# kubectl apply -f Kubernetes_Advanced_Practical/chapter11/deny-all-ingress.yaml
[root@master ~]# kubectl describe netpol/dev-allow-ingress-ns-prod -n dev
Name:         dev-allow-ingress-ns-prod
Namespace:    dev
Created on:   2021-02-02 17:10:18 +0800 CST
Labels:       <none>
Annotations:  <none>
Spec:
  PodSelector:     <none> (Allowing the specific traffic to all pods in this namespace)
+  Allowing ingress traffic:
+    To Port: <any> (traffic allowed to all ports) # 访问本地所有端口
    From:
+      NamespaceSelector: name=prod # ns
  Not affecting egress traffic
  Policy Types: Ingress

```

验证

```bash
# dev -> prod
[root@master ~]# kubectl exec -it client-pod -n prod -- sh
/ # wget -O - -q 10.244.2.2
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>
/ # wget -O - -q 10.244.3.4
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>
```

#### 指定端口

```bash
[root@master ~]# kubectl explain netpol.spec.ingress.ports | grep '>'
RESOURCE: ports <[]Object>
   port	<string>  
   protocol	<string> # 默认TCP
```

```diff
"Kubernetes_Advanced_Practical/chapter11/deny-all-ingress.yaml"
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
  namespace: dev # 不加名称空间为了通用
spec:
  podSelector: {} # 不给选择器，表示当前netpol所在名称空间中所有pod
  policyTypes:
  - Ingress        # 入站生效  ，出去不控制，默认出站允许
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: dev-allow-ingress-ns-prod
  namespace: dev
spec:
  policyTypes:
  - Ingress
  podSelector: {}  # 不给选择器，表示当前netpol所在名称空间中所有pod
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: prod     # 匹配标签为name=prod的名称空间
+    ports:
+    - port: 80
+      protocol: TCP

```

```diff
[root@master ~]# kubectl apply -f Kubernetes_Advanced_Practical/chapter11/deny-all-ingress.yaml
networkpolicy.networking.k8s.io/deny-all-ingress unchanged
networkpolicy.networking.k8s.io/dev-allow-ingress-ns-prod configured

[root@master ~]# kubectl describe netpol/dev-allow-ingress-ns-prod -n dev
Name:         dev-allow-ingress-ns-prod
Namespace:    dev
Created on:   2021-02-02 17:10:18 +0800 CST
Labels:       <none>
Annotations:  <none>
Spec:
  PodSelector:     <none> (Allowing the specific traffic to all pods in this namespace)
  Allowing ingress traffic:
+    To Port: 80/TCP     # 自已pod的80
    From:
+      NamespaceSelector: name=prod # 来自本名称空间
  Not affecting egress traffic 
+  Policy Types: Ingress # 不指定egress, 允许

```

验证client访问prod

```bash
/ # wget -O - -q 10.244.3.4
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>
/ # wget -O - -q 10.244.2.2
Hello MyApp | Version: v1 | <a href="hostname.html">Pod Name</a>

# 注意ping不通，因为仅允许80端口访问
/ # ping  10.244.2.2
PING 10.244.2.2 (10.244.2.2): 56 data bytes
^C
--- 10.244.2.2 ping statistics ---
3 packets transmitted, 0 packets received, 100% packet loss
```

```bash
# dev pod -> dev pod
[root@master ~]# kubectl exec -it myapp-7d4b7b84b-9kvr6 -- sh
/ # ping 10.244.3.4
PING 10.244.3.4 (10.244.3.4): 56 data bytes
# 阻塞
```

现在pod允许prod名称空间所有pod访问 本地80端口，但是ns内不行



### 开放dev namespace所有pod访问prod/dev ns所有pod

```bash
# dev添加标签
kubectl label ns dev name=dev 
```



```diff
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
  namespace: dev # 不加名称空间为了通用
spec:
  podSelector: {} # 不给选择器，表示当前netpol所在名称空间中所有pod
  policyTypes:
  - Ingress        # 入站生效  ，出去不控制，默认出站允许
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: dev-allow-ingress-ns-prod
  namespace: dev
spec:
  policyTypes:
+  - Ingress        # 仅控制ingress. 不给egress, 不控制，默认允许
  podSelector: {}  # 不给选择器，表示当前netpol所在名称空间中所有pod
  ingress:
  - from:
    - namespaceSelector:
+        matchExpressions:
+        - key: name # 每个名称空间上的name标签
+          operator: In # 基于集群运算
+          values: ["dev","prod"] # 值是dev/prod
-    ports:
-    - port: 80
-      protocol: TCP

```

> dev名称空间中所有pod, 可以被dev/prod名称空间访问

```diff
[root@master ~]# kubectl describe netpol/dev-allow-ingress-ns-prod -n dev
Name:         dev-allow-ingress-ns-prod
Namespace:    dev
Created on:   2021-02-02 17:10:18 +0800 CST
Labels:       <none>
Annotations:  <none>
Spec:
  PodSelector:     <none> (Allowing the specific traffic to all pods in this namespace)
  Allowing ingress traffic:
    To Port: <any> (traffic allowed to all ports)
    From:
+      NamespaceSelector: name in (dev,prod)
  Not affecting egress traffic
  Policy Types: Ingress
```

 prod的client验证，pod间验证

```bash
[root@master ~]# kubectl exec -it client-pod -n prod --  sh
/ # wget -O - -q 10.244.2.3/hostname.html
myapp-7d4b7b84b-4fknw
/ # ping 10.244.2.3
PING 10.244.2.3 (10.244.2.3): 56 data bytes
64 bytes from 10.244.2.3: seq=0 ttl=62 time=1.181 ms
64 bytes from 10.244.2.3: seq=1 ttl=62 time=1.134 ms
64 bytes from 10.244.2.3: seq=2 ttl=62 time=1.053 ms

[root@master ~]# kubectl exec -n dev -it myapp-7d4b7b84b-jhbzx -- sh 
/ #  wget -O - -q 10.244.2.3/hostname.html
myapp-7d4b7b84b-4fknw
/ #  ping 10.244.2.3
PING 10.244.2.3 (10.244.2.3): 56 data bytes
64 bytes from 10.244.2.3: seq=0 ttl=62 time=1.271 ms
64 bytes from 10.244.2.3: seq=1 ttl=62 time=1.123 ms

```

### 定义dev空间所有pod,允许所有入站，允许所有出站

由于不加策略，默认就允许，没有啥定义的。

ingress: [""] 空表示匹配所有，即允许所有

```diff
[root@master ~]# cat Kubernetes_Advanced_Practical/chapter11/deny-all-ingress.yaml 
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all-ingress
  namespace: dev # 不加名称空间为了通用
spec:
  podSelector: {} # 不给选择器，表示当前netpol所在名称空间中所有pod
  policyTypes:
+  - Ingress        # 入站生效，不定义出站，表示出站不管理，默认允许
+  ingress: 
+  - {}             # {}表示允许
```



